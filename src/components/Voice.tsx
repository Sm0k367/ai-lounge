import React, { useState, useRef, useEffect } from 'react';\nimport { Button } from './ui/button';\nimport { Mic, Volume2, StopCircle, Loader2 } from 'lucide-react';\n\nconst Voice: React.FC = () => {\n  const [isListening, setIsListening] = useState(false);\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const [transcript, setTranscript] = useState('');\n  const [response, setResponse] = useState('');\n  const recognitionRef = useRef<SpeechRecognition | null>(null);\n  const synthRef = useRef<SpeechSynthesis | null>(null);\n\n  useEffect(() => {\n    if ('webkitSpeechRecognition' in window) {\n      const SpeechRecognition = (window as any).webkitSpeechRecognition;\n      recognitionRef.current = new SpeechRecognition();\n      recognitionRef.current.continuous = true;\n      recognitionRef.current.interimResults = true;\n      recognitionRef.current.lang = 'en-US';\n\n      recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {\n        let interim = '';\n        let final = '';\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          if (event.results[i].isFinal) {\n            final += event.results[i][0].transcript;\n          } else {\n            interim += event.results[i][0].transcript;\n          }\n        }\n        setTranscript(final + interim);\n      };\n\n      recognitionRef.current.onerror = () => {\n        setIsListening(false);\n      };\n    }\n\n    synthRef.current = window.speechSynthesis;\n  }, []);\n\n  const startListening = () => {\n    const recognition = recognitionRef.current;\n    if (recognition) {\n      recognition.start();\n      setIsListening(true);\n    }\n  };\n\n  const stopListening = () => {\n    const recognition = recognitionRef.current;\n    if (recognition) {\n      recognition.stop();\n      setIsListening(false);\n    }\n  };\n\n  const speakResponse = () => {\n    const utterance = new SpeechSynthesisUtterance(response || 'Welcome to the voice lounge. How can I assist you today?');\n    utterance.rate = 0.9;\n    utterance.pitch = 1.1;\n    synthRef.current?.speak(utterance);\n    setIsSpeaking(true);\n\n    utterance.onend = () => setIsSpeaking(false);\n  };\n\n  const handleSubmit = () => {\n    if (transcript.trim()) {\n      // Mock AI response\n      const responses = [\n        'That\\'s fascinating! Voice interaction in AI lounges opens up new dimensions of human-AI collaboration.',\n        'Excellent point. Real-time speech synthesis is revolutionizing content creation and accessibility.',\n        'Love the energy! Combining voice with generative AI creates truly immersive experiences.',\n      ];\n      setResponse(responses[Math.floor(Math.random() * responses.length)]);\n      speakResponse();\n    }\n  };\n\n  return (\n    <div className=\"flex-1 flex flex-col bg-black/50 backdrop-blur-xl rounded-2xl border border-pink-500/30 p-8 max-w-4xl mx-auto w-full h-[80vh] neon-glow overflow-hidden\">\n      <div className=\"flex items-center gap-3 mb-6 pb-4 border-b border-pink-500/30\">\n        <Mic className=\"w-8 h-8 text-pink-400 animate-pulse\" />\n        <div>\n          <h3 className=\"text-xl font-bold bg-gradient-to-r from-pink-400 via-purple-400 to-cyan-400 bg-clip-text text-transparent\">\n            Voice Lounge\n          </h3>\n          <p className=\"text-sm text-pink-300/80\">Talk to AI - real-time voice chat</p>\n        </div>\n      </div>\n\n      <div className=\"flex-1 space-y-6 overflow-y-auto pr-2 scrollbar-thin scrollbar-thumb-pink-500/50 scrollbar-track-transparent\">\n        {transcript && (\n          <div className=\"p-6 rounded-2xl bg-gradient-to-r from-blue-600/20 to-cyan-600/20 border border-blue-500/40 neon-glow\">\n            <div className=\"font-mono text-lg mb-2\">You:</div>\n            <div>{transcript}</div>\n          </div>\n        )}\n        {response && (\n          <div className=\"p-6 rounded-2xl bg-gradient-to-r from-purple-600/20 to-pink-600/20 border border-purple-500/40 neon-glow\">\n            <div className=\"font-mono text-lg mb-2 flex items-center gap-2\">\n              <Bot className=\"w-6 h-6\" />\n              AI:\n            </div>\n            <div>{response}</div>\n          </div>\n        )}\n      </div>\n\n      <div className=\"space-y-4 pt-4 border-t border-pink-500/30\">\n        <div className=\"flex gap-3 items-center\">\n          <Button\n            onClick={isListening ? stopListening : startListening}\n            size=\"lg\"\n            className={`flex-1 neon-btn ${isListening ? 'bg-gradient-to-r from-red-500 to-pink-500' : 'bg-gradient-to-r from-pink-500 to-purple-500'}`}\n          >\n            {isListening ? (\n              <>\n                <StopCircle className=\"w-6 h-6 mr-2 animate-spin\" />\n                Stop Listening\n              </>\n            ) : (\n              <>\n                <Mic className=\"w-6 h-6 mr-2 animate-pulse\" />\n                Start Voice\n              </>\n            )}\n          </Button>\n          <Button\n            onClick={handleSubmit}\n            disabled={!transcript.trim()}\n            variant=\"secondary\"\n            size=\"lg\"\n            className=\"neon-glow border-pink-400 bg-gradient-to-r from-pink-500/30 to-purple-500/30\"\n          >\n            <Volume2 className=\"w-6 h-6 mr-2\" />\n            AI Respond\n          </Button>\n        </div>\n        {isSpeaking && (\n          <div className=\"flex items-center gap-2 text-pink-400 animate-pulse\">\n            <Loader2 className=\"w-5 h-5 animate-spin\" />\n            <span>AI is speaking...</span>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n\nexport default Voice;\n